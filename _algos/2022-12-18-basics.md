---
permalink: /algos/basics
title: "The Starting Point"
layout: single
classes: wide
toc: true
toc_label: "The Starting Point: My Table of Contents"
toc_icon: "cog"
excerpt: "The meat and potatoes of algorithms."
header:
  image: /assets/img/algos/basics/roadmap.png
  teaser: /assets/img/algos/basics/header-image.png
---
# Prologue
Alright, let's get technical. As I mentioned, we're going to start off
with most of the fundamentals someone needs. This post is relatively lengthy
and has two major sections but I've decided to keep all of this in one post,
rather than two since they're related.

#  Data Types
Let's begin by talking about the kind of data that we expect our algorithms
to work on. We need to be able to represent (at the minimum) the following:

1. Truth Values
2. Integers
3. Fractions
4. Alphabetical Characters (and Beyond)
5. References to Data Objects

## Bits
First of all, most modern computer systems [^1] like to store information
using bits. For our current intents and purposes, you can just take it to
mean that anything that we wish to store, the computer has to, and will
do it in the form of storing a sequence of values in $$0$$'s and $$1$$'s.

In your RAM sticks, in your hard drives, even when the data is 
being operated on in the CPU, it's all really just bits 
whizzing about circuits.

Let's see how the most important data types we want are represented.

## Booleans/Truth Values
It's going to be quite common that we need to evaluate the "truth value"
of a given statement. Take for example the following that tests to see
if a given number `a` is larger than the square root of another `b`:

{% highlight python %}
def square_test(a, b):
    # assumes both a and b are positive
    truth_value = (a * a) > b
    return truth_value
{% endhighlight %}

Think for a second about what the computer should store in `truth_value`
if it only sees bits. In Python (or a similar programming language)
we expect the type that is returned to be a boolean type 
that takes on value `True` or `False`. Most often, in computers 
this is represented by `1` and `0` respectively.

Often times, programming languages also like to treat these as `1` and 
`0` respectively. For example, in C/C++ it is possible to treat Boolean
values as integers and therefore do arithmetic or comparisons with 
other integers on them. An important distinction has to be made that 
when a programming language does it, it's an interpretation that 
`True` _can be viewed_ as `1` (and `False` as `0`). Booleans are not
integers, after all. 
_They may be represented the same way by computers but semantically, there is a difference between a "truth value" and an "integer"_.
{: .notice} 

## Representing Numbers and other Numerical Values
You might be used to seeing integers in represented in base 10, like so:
* 123
* 00123
* -270

In general, a number in base 10 is represented in the following way:

![](/assets/img/algos/basics/decimal.png){: style="width:100%; height:auto;"}
Base 10 in general.
{: style="color:gray; font-size: 80%; text-align: center;"}

However, there's really nothing stopping
us from using base 2 instead. In fact, that's how
your computer stores integers. So any number 
can actually be decomposed into the following form:

$$ \sum_i b_i \cdot 2^i $$

Here are some examples:
* $$ 3 =  1 * \left(1\right) + 1 * \left(2\right)  $$
* $$ 5 =  1 * \left(1\right) + 0 * \left(2\right) + 1 * \left(4\right)$$
* $$ 13 = 1 * \left(1\right) + 0 * \left(2\right) + 1 * \left(4\right) + 1 * \left(8\right)$$

So in binary, we would represent them like so:

![example representations](/assets/img/algos/basics/conversion-example.png)
What you see as opposed to what your computer sees.
{: style="color:gray; font-size: 80%; text-align: center;"}

Now theoretically, we could keep this going on forever. 
A small problem is that the arithmetic logic units (ALU) of 
modern processors can't operate on arbitrarily many bits
and as a consequence the maximum possible value represented
is actually limited. Typically, they allow up to either 32 bits, or 64 bits.
So, the largest possible value we can represent up to is either 
$$2^{32} - 1$$ or $$2^{64} - 1$$. For convention, whenever concerned, 
we will from now on take the integer representation to be using $$64$$ bits.

**Unsigned Integers**: For integers that are non-negative, can store them as _unsigned integers_ 
in the manner as described above.
{: .notice--success}

### Adding Unsigned Integers
Now that we've introduced unsigned integers, let's cover addition up front (because it actually 
influences the way we represent the other numerical values).

**Question:** How would you add two numbers in binary?
{: .notice--primary}

It's actually really similar to how you would do it in decimal. Here's a simple sketch with
only $$4$$ bits:

![addition](/assets/img/algos/basics/addition-algo.png)
Addition algorithm on $$4$$ bits.
{: style="color:gray; font-size: 80%; text-align: center;"}

The fact that we discard the carry at the end makes our addition algorithm behave as sort of a 
"wraparound". So really think of this addition algorithm on $$4$$ bits as computing
$$(a + b)\  mod\  2^{4}$$.


### Signed Integers
But what about negative values? How should we represent them? One way would be to use one of the bits
to mark whether it's negative.

![Signed Integer](/assets/img/algos/basics/ones-complement.png)
Signed Representation.
{: style="color:gray; font-size: 80%; text-align: center;"}

But then we would need to first check the sign bit to see what kind of integers are involved,
and more importantly, based on that we need to either invoke the addition algorithm
or a subtraction algorithm.

Instead, it would be ideal to reuse the addition algorithm especially if we can use a representation 
which doesn't cost anything (compared to checking a sign bit before invoking either algorithm).

Recall that the addition algorithm we introduced for $$4$$ bits basically adds up to $$2^4 - 1= 15$$ before
wrapping around again. For example, $$2$$ and $$15$$ would be added to $$1$$ (try it). So what we can
do, is "reinterpret" the number line from $$0$$ to $$15$$ to accomodate for negative numbers. 
You can think of $$15$$ as being "$$1$$ away from $$0$$" which is basically $$-1$$.
In general, with $$4$$ bits, we would like to think of each number $$-x$$ as $$16 - x$$. The slight caveat 
is that with $$4$$ bits we can only represent $$16$$ numbers, so what we do is spend 
$$8$$ of them representing $$0$$ to $$7$$, and the remaining numbers representing $$-8$$ to $$-1$$.

![Which numbers we choose to represent](/assets/img/algos/basics/number-line-with-chosen.png)
Which numbers we choose to represent.
{: style="color:gray; font-size: 80%; text-align: center;"}

So if you're given a number like $$5$$ ($$0101$$ in binary), what would be its negative 
equivalent? It would be $$16 - 5 = 11$$ ($$1011$$ in binary). The nice thing now is that we 
can add any two numbers between $$-8$$ and $$7$$ and it just works, as long as we interpret 
our negative numbers in the way that I've mentioned.

Now a "quick" way for computers to convert numbers to their negatives, is to do the following:

![How processors actually negate numbers](/assets/img/algos/basics/fast-conversion.png)
How processors actually negate numbers.
{: style="color:gray; font-size: 80%; text-align: center;"}

This might sound like magic, but that's really happening is that we're really just computing
$$16 - x$$. Think of it this way: $$1111_2$$ is $$15 = 2^4 - 1$$. So subtracting a number from $$15$$
, like $$4$$, just removes the bits from $$15$$ that $$4$$ has. In which case, we would get $$1011_2$$.
This holds regardless of what number we're subtracting from $$15$$, as long as it's at most $$15$$ (try it!).

"Removing bits from $$1111_2$$" is really just the same as flipping all of the bits. Now, we really wanted $$16 - x$$, not $$16 - 1 - x$$. So, what we need to do, is add $$1$$ after flipping the bits.

Et voila! Welcome to what is known as [two's complement](https://en.wikipedia.org/wiki/Two%27s_complement).

**Signed integers**: For integers that _might be_ negative, can store them as integers_ 
in the manner as described above. Note that signed integers and unsigned integers are different types.
So adding unsigned integers to signed integers might produce unexpected results since the type tells us
how we should be interpreting the numbers.
{: .notice--success}

In practice, you can make signed and unsigned integers for 32bits, 64 bits, and so on. We can only expect them to go up as large as $$2^{63} - 1$$ for unsigned, or 
$$2^{62} - 1$$ for signed integers.
{: .notice} 

## What about fractions? Decimal points?
What happens if we want to represent numbers in between integers? What about $$\frac{1}{3}$$? What about 
$$0.55$$? Relating it back to the decimal system that we're all comfortable with, we can try a format 
that looks something like this:

![](/assets/img/algos/basics/decimal-rep.png)
An example of how we might begin to start storing fractional values.
{: style="color:gray; font-size: 80%; text-align: center;"}

We've not completely dodged the issue, we somehow still need to store a "fractional" value in the mantissa
although now the possible range is restricted from $$1$$ to $$10$$ (in some sense). Worse still, it's still 
very unclear how we would store something like $$1/3$$, which actually can't be finitely written in a decimal 
point system.

The sad fact is that, we won't be able to store values up to an arbitrary precision. In practice, 
what is actually done is that we have a limited set of fractions that we can make. I'll explain this but 
based on the binary system.

## Arrays, Strings, and Big Integers

## Pointers and References

## Composing Into More Complicated Types

# Basic Operations
## The Computational Model


## Copying vs. Moving

## Subroutines

## A Philosophical Aside

# The Efficiency of Algorithms
## Time and Space Complexity

## The Notion of Asymptotics
### Bachmann–Landau Notation 

### The Limits of Asymptotics: Where the real world departs from the model

# What Next?

---
[^1]: I say most, because things like ternary CMOS and quantum computers exist.